{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e584649",
   "metadata": {},
   "source": [
    "Web -> Bedrock -> Translate -> Comprehend -> S3\n",
    "\n",
    "这个 Jupyter 风格的 notebook（以 `# %%` 单元格分隔）展示了一个可复现的处理流水线：\n",
    "1. 用 `requests` 抓取网页并用 BeautifulSoup 抽取正文\n",
    "2. 可选：把正文发送给 Amazon Bedrock 做清洗/摘要（若配置了 Bedrock 模型）\n",
    "3. 用 Amazon Translate 翻译为英文\n",
    "4. 用 Amazon Comprehend 做情感分析\n",
    "5. 将结果序列化并上传到 S3\n",
    "\n",
    "假定你已经在机器上运行过 `aws configure` 或者已通过环境变量/角色方式配置好凭证。\n",
    "请不要把凭证写到 notebook 中。\n",
    "\n",
    "在运行前，请 `pip install -r requirements.txt`，或者运行下面的安装单元格。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162dd70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 安装（可选）\n",
    "!pip install boto3 requests beautifulsoup4 readability-lxml python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e68732d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置项 (请根据你自己的环境修改)\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import hashlib\n",
    "import logging\n",
    "from typing import List, Tuple, Dict, Any\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError, BotoCoreError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b068204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"web-pipeline\")\n",
    "\n",
    "# 环境变量配置（可用 aws configure 或环境变量）\n",
    "AWS_REGION = os.environ.get(\"AWS_REGION\", \"eu-west-1\")\n",
    "S3_BUCKET = os.environ.get(\"RESULT_S3_BUCKET\", \"my-result-bucket\")\n",
    "BEDROCK_MODEL_ID = os.environ.get(\"BEDROCK_MODEL_ID\", \"\")  # 若不使用 Bedrock 可留空\n",
    "\n",
    "# boto3 clients\n",
    "s3 = boto3.client(\"s3\", region_name=AWS_REGION)\n",
    "translate = boto3.client(\"translate\", region_name=AWS_REGION)\n",
    "comprehend = boto3.client(\"comprehend\", region_name=AWS_REGION)\n",
    "# Bedrock 的 client 名称在 boto3 中为 'bedrock-runtime'（需要 SDK 支持）\n",
    "bedrock = boto3.client(\"bedrock-runtime\", region_name=AWS_REGION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec72fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) 抓取网页并抽取正文\n",
    "\n",
    "def fetch_page_text(url: str, timeout: int = 10) -> str:\n",
    "    \"\"\"使用 requests + BeautifulSoup 做简单的正文抽取。\n",
    "\n",
    "    策略：先尝试 <article> 标签；若无则合并所有 <p> 段落。\n",
    "    返回纯文本（去掉多余空白）。\n",
    "    \"\"\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (compatible; web-pipeline/1.0)\"}\n",
    "    resp = requests.get(url, timeout=timeout, headers=headers)\n",
    "    resp.raise_for_status()\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "    # 尝试常见正文容器\n",
    "    candidates = []\n",
    "    article = soup.find(\"article\")\n",
    "    if article:\n",
    "        candidates.append(article.get_text(separator=\"\\n\", strip=True))\n",
    "\n",
    "    # 常见类名（简化）\n",
    "    for cls in (\"main\", \"content\", \"post\", \"article-body\", \"entry-content\"):\n",
    "        el = soup.find(class_=cls)\n",
    "        if el:\n",
    "            candidates.append(el.get_text(separator=\"\\n\", strip=True))\n",
    "\n",
    "    # fallback: 拼接所有 <p>\n",
    "    if not candidates:\n",
    "        paragraphs = soup.find_all(\"p\")\n",
    "        text = \"\\n\\n\".join(p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True))\n",
    "    else:\n",
    "        # 选最长的候选者\n",
    "        text = max(candidates, key=len)\n",
    "\n",
    "    # 清理多余空白\n",
    "    text = \"\\n\".join(line.strip() for line in text.splitlines() if line.strip())\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7011d0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) （可选）调用 Bedrock 对文本做清洗/去噪/结构化\n",
    "\n",
    "def bedrock_clean_text(text: str, model_id: str = BEDROCK_MODEL_ID, timeout_seconds: int = 60) -> str:\n",
    "    \"\"\"如果配置了 BEDROCK_MODEL_ID，则把 `text` 发给 Bedrock 的模型，让模型返回清洗后的文本。\n",
    "\n",
    "    如果未配置 model_id，则直接返回原文。\n",
    "\n",
    "    注意：Bedrock 不会去抓 URL，它只处理你传入的字符串。\n",
    "    返回值取决于你使用的模型与 prompt。示例使用最简单的 prompt。\n",
    "    \"\"\"\n",
    "    if not model_id:\n",
    "        logger.info(\"No Bedrock model configured, skipping Bedrock step.\")\n",
    "        return text\n",
    "\n",
    "    prompt = (\n",
    "        \"You are a text-cleaning assistant.\\n\"\n",
    "        \"Given a noisy HTML-extracted article text, return a cleaned, readable plaintext article.\\n\\n\"\n",
    "        \"ARTICLE:\\n\" + text + \"\\n\\nCLEANED ARTICLE:\\n\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # invoke_model 的参数与返回结构可能随 SDK 版本不同，请参考你当前环境的 boto3 文档。\n",
    "        response = bedrock.invoke_model(\n",
    "            modelId=model_id,\n",
    "            contentType=\"text/plain; charset=utf-8\",\n",
    "            accept=\"application/json\",\n",
    "            body=prompt.encode(\"utf-8\")\n",
    "        )\n",
    "        # response['body'] 是一个 StreamingBody\n",
    "        body_bytes = response[\"body\"].read()\n",
    "        cleaned = body_bytes.decode(\"utf-8\")\n",
    "        # 有些模型会把整个 JSON 或带前缀输出，你可以在这里对 cleaned 做额外处理\n",
    "        return cleaned\n",
    "    except (ClientError, BotoCoreError) as e:\n",
    "        logger.exception(\"Bedrock invocation failed, returning original text: %s\", e)\n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10280965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) 对长文本做分片（因为 Translate / Comprehend 有长度限制）\n",
    "\n",
    "def split_text_chunks(text: str, max_chars: int = 4500) -> List[str]:\n",
    "    \"\"\"按段落分割并组合成不超过 max_chars 的块。\n",
    "    4500 字符是一个经验值：Translate/Comprehend 的实际限制请查官方文档。\n",
    "    \"\"\"\n",
    "    paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n",
    "    chunks = []\n",
    "    cur = []\n",
    "    cur_len = 0\n",
    "    for p in paragraphs:\n",
    "        if len(p) > max_chars:\n",
    "            # 如果单个段落超长，再按句子或固定长度切分\n",
    "            for i in range(0, len(p), max_chars):\n",
    "                piece = p[i:i+max_chars]\n",
    "                if cur:\n",
    "                    chunks.append('\\n\\n'.join(cur))\n",
    "                    cur = []\n",
    "                    cur_len = 0\n",
    "                chunks.append(piece)\n",
    "        else:\n",
    "            if cur_len + len(p) + 2 > max_chars:\n",
    "                chunks.append('\\n\\n'.join(cur))\n",
    "                cur = [p]\n",
    "                cur_len = len(p)\n",
    "            else:\n",
    "                cur.append(p)\n",
    "                cur_len += len(p) + 2\n",
    "    if cur:\n",
    "        chunks.append('\\n\\n'.join(cur))\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f029b24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) 翻译（把每个 chunk 发给 Translate，然后拼回去）\n",
    "\n",
    "def translate_chunks_to_english(chunks: List[str]) -> Tuple[str, str]:\n",
    "    \"\"\"将每个文本块翻译成英文并合并，返回 (full_translated_text, detected_source_language)\n",
    "    detected_source_language 取第一个块的返回值作为代表。\n",
    "    \"\"\"\n",
    "    translated_parts = []\n",
    "    detected_lang = None\n",
    "    for chunk in chunks:\n",
    "        try:\n",
    "            resp = translate.translate_text(Text=chunk, TargetLanguageCode=\"en\")\n",
    "            translated_parts.append(resp.get(\"TranslatedText\", \"\"))\n",
    "            if detected_lang is None:\n",
    "                detected_lang = resp.get(\"SourceLanguageCode\")\n",
    "        except (ClientError, BotoCoreError) as e:\n",
    "            logger.exception(\"Translate failed for a chunk, adding original chunk instead: %s\", e)\n",
    "            translated_parts.append(chunk)\n",
    "    return \"\\n\\n\".join(translated_parts), (detected_lang or \"unknown\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005b574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5) 情感分析（对已翻译的英文文本使用 Comprehend）\n",
    "\n",
    "def analyze_sentiment_for_text(text: str, language_code: str = \"en\") -> Dict[str, Any]:\n",
    "    \"\"\"若文本过长，按块调用 detect_sentiment，然后合并得分。\n",
    "    返回总体情感标签（majority 或基于分数合成）和每块的细节。\n",
    "    \"\"\"\n",
    "    chunks = split_text_chunks(text, max_chars=4500)\n",
    "    results = []\n",
    "    # Comprehend detect_sentiment 每次处理一段文本\n",
    "    for chunk in chunks:\n",
    "        try:\n",
    "            resp = comprehend.detect_sentiment(Text=chunk, LanguageCode=language_code)\n",
    "            results.append(resp)\n",
    "        except (ClientError, BotoCoreError) as e:\n",
    "            logger.exception(\"Comprehend detect_sentiment failed for a chunk: %s\", e)\n",
    "            results.append({\"Sentiment\": \"ERROR\", \"SentimentScore\": {}})\n",
    "\n",
    "    # 合并逻辑：对各情感分数求平均\n",
    "    score_sum = {\"Positive\": 0.0, \"Negative\": 0.0, \"Neutral\": 0.0, \"Mixed\": 0.0}\n",
    "    valid = 0\n",
    "    for r in results:\n",
    "        sc = r.get(\"SentimentScore\") or {}\n",
    "        if sc:\n",
    "            valid += 1\n",
    "            for k in score_sum.keys():\n",
    "                score_sum[k] += float(sc.get(k, 0.0))\n",
    "    if valid > 0:\n",
    "        avg_score = {k: v / valid for k, v in score_sum.items()}\n",
    "        # 选平均分最高的情感作为总体情感\n",
    "        overall_sentiment = max(avg_score.items(), key=lambda x: x[1])[0]\n",
    "    else:\n",
    "        avg_score = {}\n",
    "        overall_sentiment = \"UNKNOWN\"\n",
    "\n",
    "    return {\n",
    "        \"overall_sentiment\": overall_sentiment,\n",
    "        \"average_scores\": avg_score,\n",
    "        \"per_chunk\": results,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba50a805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) 上传 JSON 到 S3\n",
    "\n",
    "def upload_json_to_s3(obj: Dict[str, Any], key: str) -> str:\n",
    "    body = json.dumps(obj, ensure_ascii=False, indent=None).encode(\"utf-8\")\n",
    "    try:\n",
    "        s3.put_object(Bucket=S3_BUCKET, Key=key, Body=body, ContentType=\"application/json; charset=utf-8\")\n",
    "    except ClientError:\n",
    "        logger.exception(\"Failed to upload result to S3\")\n",
    "        raise\n",
    "    return f\"s3://{S3_BUCKET}/{key}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab81c945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) 把所有步骤串成一个 `process_url` 函数\n",
    "\n",
    "def process_url(url: str, do_bedrock_clean: bool = True) -> Dict[str, Any]:\n",
    "    start = time.time()\n",
    "    logger.info(\"Processing URL: %s\", url)\n",
    "    raw_text = fetch_page_text(url)\n",
    "    if not raw_text or len(raw_text.strip()) == 0:\n",
    "        logger.warning(\"No textual content extracted from %s\", url)\n",
    "        return {\"url\": url, \"status\": \"no_content\"}\n",
    "\n",
    "    cleaned_text = raw_text\n",
    "    if do_bedrock_clean and BEDROCK_MODEL_ID:\n",
    "        cleaned_text = bedrock_clean_text(raw_text, model_id=BEDROCK_MODEL_ID)\n",
    "\n",
    "    chunks = split_text_chunks(cleaned_text)\n",
    "    translated_text, src_lang = translate_chunks_to_english(chunks)\n",
    "\n",
    "    # 使用英文情感分析（因为我们已翻译为英文）\n",
    "    sentiment = analyze_sentiment_for_text(translated_text, language_code=\"en\")\n",
    "\n",
    "    result = {\n",
    "        \"source_url\": url,\n",
    "        \"detected_source_language\": src_lang,\n",
    "        \"raw_text_excerpt\": raw_text[:2000],\n",
    "        \"cleaned_text_excerpt\": cleaned_text[:2000],\n",
    "        \"translated_text_excerpt\": translated_text[:2000],\n",
    "        \"sentiment\": sentiment,\n",
    "        \"meta\": {\n",
    "            \"char_counts\": {\n",
    "                \"raw\": len(raw_text),\n",
    "                \"cleaned\": len(cleaned_text),\n",
    "                \"translated\": len(translated_text),\n",
    "            },\n",
    "            \"processing_time_sec\": time.time() - start,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # 使用 URL 的 sha1 + 时间戳 作为对象 key\n",
    "    key = f\"results/{hashlib.sha1(url.encode()).hexdigest()}_{int(time.time())}.json\"\n",
    "    s3_uri = upload_json_to_s3(result, key)\n",
    "    result[\"s3_uri\"] = s3_uri\n",
    "    logger.info(\"Finished %s -> %s\", url, s3_uri)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eb29f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Demo: 处理单个或多个 URL\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 交互式示例：把要处理的 URL 列表放到 urls 里\n",
    "    urls = [\n",
    "        # 请替换成你想处理的 URL\n",
    "        \"https://example.com/some-article\",\n",
    "    ]\n",
    "    for u in urls:\n",
    "        try:\n",
    "            out = process_url(u, do_bedrock_clean=False)  # demo：不使用 Bedrock\n",
    "            print(json.dumps(out, ensure_ascii=False, indent=2))\n",
    "        except Exception as e:\n",
    "            logger.exception(\"Error processing %s: %s\", u, e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c32c16",
   "metadata": {},
   "source": [
    "\n",
    "9) 扩展建议与注意事项\n",
    "- 不要在 notebook 中存储 AWS 密钥。\n",
    "- 在处理大量 URL 时，建议将 URL 放入队列（SQS / Kafka / Redis），并用多 worker 并发处理。\n",
    "- 本 notebook 的分片长度（4500）是经验值，Translate/Comprehend 的具体限制请以官方文档为准。\n",
    "- Bedrock 调用方式会随 AWS SDK 版本变化，若 `bedrock-runtime` 客户端不可用，请参考 AWS 官方示例或更新 boto3。\n",
    "- 为生产环境添加重试（指数回退）、指标监控（CloudWatch）和成本控制（预算告警）。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
